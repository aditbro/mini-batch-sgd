{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import arff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def init_weight(self, nb_input=0):\n",
    "        self.nb_input = nb_input\n",
    "        self.weights = [random.random() * 0.0001 for x in range(nb_input)]\n",
    "        self.bias = 1\n",
    "        self.bias_delta = 0\n",
    "        self.prev_bias_delta = 0\n",
    "        self.prev_delta = [0 for x in range(nb_input)]\n",
    "        self.current_delta = [0 for x in range(nb_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, nb_nodes=1, learning_rate=0, momentum=0):\n",
    "        self.nb_nodes = nb_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nodes = [Node() for x in range(nb_nodes)]\n",
    "        self.input = []\n",
    "        self.output = [0 for x in range(nb_nodes)]\n",
    "        self.nb_input = 0\n",
    "        \n",
    "    def init_weight(self):\n",
    "        for node in self.nodes:\n",
    "            node.init_weight(nb_input=self.nb_input)\n",
    "            \n",
    "    def calculate_output(self):\n",
    "        for i in range(len(self.nodes)):\n",
    "            total = sum([self.input[x] * self.nodes[i].weights[x] for x in range(len(self.input))])\n",
    "            total += self.nodes[i].bias\n",
    "            self.output[i] = self.sigmoid(total)\n",
    "            \n",
    "    def sigmoid(self, n):\n",
    "#         try:\n",
    "            return 1/(1 + np.exp(-n))\n",
    "#         except Exception as e:\n",
    "#             print(n)\n",
    "#             if n > 2000: return 1.0\n",
    "#             if n < -2000: return 0\n",
    "    \n",
    "    def calculate_output_delta(self, target=0):\n",
    "        for i in range(len(self.nodes)):\n",
    "            node = self.nodes[i]\n",
    "            self.dk = self.output[i] * (1 - self.output[i]) * (target - self.output[i])\n",
    "            \n",
    "            for j in range(len(node.weights)):\n",
    "                delta = node.current_delta[j] + (self.learning_rate * self.dk * self.input[j])\n",
    "                node.prev_delta[j] = node.current_delta[j]\n",
    "                node.current_delta[j] = delta\n",
    "                \n",
    "            delta = node.bias_delta + (self.learning_rate * self.dk)\n",
    "            node.prev_bias_delta = node.bias_delta\n",
    "            node.bias_delta = delta\n",
    "                \n",
    "    def calculate_delta(self, next_layer=None):\n",
    "        for i in range(len(self.nodes)):\n",
    "            node = self.nodes[i]\n",
    "            sum_delta = self.calculate_sum_delta(idx=i, next_layer=next_layer)\n",
    "            self.dk = self.output[i] * (1 - self.output[i]) * sum_delta\n",
    "            \n",
    "            for j in range(len(node.weights)):\n",
    "                delta = node.current_delta[j] + (self.learning_rate * self.dk * self.input[j])\n",
    "                node.prev_delta[j] = node.current_delta[j]\n",
    "                node.current_delta[j] = delta\n",
    "                \n",
    "            delta = node.bias_delta + (self.learning_rate * self.dk)\n",
    "            \n",
    "    def calculate_sum_delta(self, idx=0, next_layer=None):\n",
    "        return sum([node.weights[idx] * next_layer.dk for node in next_layer.nodes])\n",
    "            \n",
    "        \n",
    "    def update_weight(self):\n",
    "        for node in self.nodes:\n",
    "            node.bias = node.bias + node.bias_delta + (self.momentum * node.prev_bias_delta)\n",
    "            node.prev_bias_delta = node.bias_delta\n",
    "            for i in range(len(node.weights)):\n",
    "                node.weights[i] = node.weights[i] + node.current_delta[i] + (self.momentum * node.prev_delta[i])\n",
    "                node.prev_delta[i] = node.current_delta[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchSGDClassifier():\n",
    "    def __init__(self, batch_size=1, learning_rate=0.1, momentum=0.1, nb_epoch=1):\n",
    "        self.layers = []\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.batches = []\n",
    "        \n",
    "    def add_layer(self, nb_nodes=1):\n",
    "        self.layers.append(Layer(nb_nodes=nb_nodes, learning_rate=self.learning_rate, momentum=self.momentum))\n",
    "        \n",
    "    def set_training_data(self, x=[], y=[]):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        for i in range(math.ceil(len(x)/self.batch_size)):\n",
    "            current_batch = []\n",
    "            offset = i * self.batch_size\n",
    "\n",
    "            for j in range(self.batch_size):\n",
    "                current_batch.append({\n",
    "                    'x': self.x[offset + j],\n",
    "                    'y': self.y[offset + j]\n",
    "                })\n",
    "            \n",
    "            self.batches.append(current_batch)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.init_weight()\n",
    "        for _ in range(self.nb_epoch):\n",
    "            for batch in self.batches:\n",
    "                for data in batch:\n",
    "                    self.feed_forward(data)\n",
    "                    self.backward_propagate(data)\n",
    "                self.update_weight()\n",
    "            \n",
    "    \n",
    "    def feed_forward(self, data):\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                self.layers[0].input = data['x']\n",
    "            else:\n",
    "                self.layers[i].input = self.layers[i-1].output\n",
    "            self.layers[i].calculate_output()\n",
    "            \n",
    "    def backward_propagate(self, data):\n",
    "        for i in range(0, len(self.layers)):\n",
    "            idx = len(self.layers) - i - 1\n",
    "            \n",
    "            if idx == len(self.layers) - 1 :\n",
    "                self.layers[idx].calculate_output_delta(target=data['y'])\n",
    "            else:\n",
    "                self.layers[idx].calculate_delta(next_layer=self.layers[idx+1])\n",
    "                \n",
    "    def update_weight(self):\n",
    "        for layer in self.layers:\n",
    "            layer.update_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                self.layers[0].nb_input = len(self.batches[0][0]['x'])\n",
    "            else :\n",
    "                self.layers[i].nb_input = self.layers[i-1].nb_nodes\n",
    "            \n",
    "            self.layers[i].init_weight()\n",
    "            \n",
    "    def predict(self, data):\n",
    "        self.feed_forward(data)\n",
    "        return self.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [0.3298820691272408], target: 1\n",
      "result: [0.39019512801285144], target: 0\n",
      "result: [0.34754795830375823], target: 0\n",
      "result: [0.3428951435005561], target: 1\n",
      "result: [0.8236695703846506], target: 1\n",
      "result: [0.8231091955016749], target: 1\n",
      "66.66666666666666 %\n"
     ]
    }
   ],
   "source": [
    "data = arff.load(open('weather.arff', 'r'))\n",
    "outlook_dict = {'rainy': 50, 'overcast': 75, 'sunny': 100}\n",
    "windy_dict = {'TRUE': 50, 'FALSE': 100}\n",
    "play_dict = {'yes': 1, 'no': 0}\n",
    "\n",
    "for i in range(len(data['data'])):\n",
    "    data['data'][i][0] = outlook_dict[data['data'][i][0]]\n",
    "    data['data'][i][3] = windy_dict[data['data'][i][3]]\n",
    "    data['data'][i][4] = play_dict[data['data'][i][4]]\n",
    "\n",
    "random.shuffle(data['data'])\n",
    "x = [x[0:4] for x in data['data']]\n",
    "y = [x[4] for x in data['data']]\n",
    "x1 = [x[0:4] for x in data['data'][8:]]\n",
    "y1 = [x[4] for x in data['data'][8:]]\n",
    "\n",
    "sgd = MiniBatchSGDClassifier(batch_size=1, learning_rate=10e-5, momentum=0.9, nb_epoch=100)\n",
    "sgd.set_training_data(x=x, y=y)\n",
    "sgd.add_layer(nb_nodes=10)\n",
    "sgd.add_layer(nb_nodes=1)\n",
    "sgd.fit()\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    result = sgd.predict(data={'x': x1[i]})\n",
    "    print('result: {}, target: {}'.format(result,y1[i]))\n",
    "    if(abs(y1[i] - result[0]) < 0.5):\n",
    "        total_correct += 1\n",
    "        \n",
    "print(total_correct/len(x1) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
